---
title: About
description: About AlignTrue.
---

# About AlignTrue

## What

**AlignTrue keeps your AI rules in sync across agents, projects, and people.**

- **Solo devs:** One source of truth for Cursor `.mdc`, `AGENTS.md`, `CLAUDE.md`, and whatever else you use.
- **Teams:** Shared rules that actually stay aligned across IDEs, agents, and repos, so best practices are practiced and not just vibes.

AlignTrue is [MIT licensed](https://github.com/AlignTrue/aligntrue/blob/main/LICENSE) and mostly self-documenting. If something is broken, outdated, or missing, open a PR.

## Why

I went deep with AI agents (especially when Sonnet 4.5 landed) and burned an irresponsible number of tokens fast. The power is obvious. So is the failure mode.

Most people aren't failing because AI is weak. They're failing because their guidance is scattered, inconsistent, and stale. Rules drift. Different agents see different instructions. Teams quietly invent their own "norms" and the AI just amplifies the chaos.

In regulated work, where you can't ship what you can't explain, I explored the problem from the interpretability side with [GlassAlpha](https://glassalpha.com). That surfaced a deeper issue: if your rules aren't aligned, nothing else is.

So, alignTrue starts further upstream: make it trivial to define, reuse, and sync rules everywhere so you get **leverage instead of chaos**.

I believe a meaningful chunk of future GDP growth is locked behind bad AI usage, not bad AI models. AlignTrue is how we fix that binding constraint to unlock what comes next ðŸš€

## Who

I'm [Gabe Mays](https://gmays.com/about/). I love building tools that close the gap between AI hype and real output.
