---
title: About
description: A bit about AlignTrue.
---

# About AlignTrue

## What

AlignTrue keeps your AI rules in sync across agents, projects, and people.

- **Solo devs:** One source of truth for Cursor `.mdc`, `AGENTS.md`, `CLAUDE.md`, and whatever else youâ€™re experimenting with.
- **Teams:** Shared rules that actually stay aligned across IDEs, agents, and repos, so best practices are practiced and not just vibes.

AlignTrue is [MIT licensed](LICENSE) and designed to be self-documenting. If something is confusing, wrong, needs fixing or extending, please open a PR!

## Who

I'm [Gabe Mays](https://gmays.com/about/). I love building tools that close the gap between AI hype and real output.

## Why

I went deep with AI agents (especially when Sonnet 4.5 was released) and spent an irresponsible number of tokens in a short amount of time. I found the power is obvious, but the failure mode is too.

Most people aren't failing because AI sucks, but because they aren't guiding well enough. Rules drift. Different agents see different guidance. Teams silently fork their own "norms" and the AI just amplifies the chaos.

In regulated industries (where you can't ship what you can't explain) I explored this from the interpretability side with [GlassAlpha](https://glassalpha.com). That's when this alignment issue with rules nerd-sniped me and here I am!

AlignTrue starts earlier in the chain: make it trivial to define, reuse, and sync rules everywhere so humans and agents work from the same playbook.

It scratches my own itch, lays the foundation for better workflows, and it is open so we can all move faster together.

This is just the beginning, stay tuned!

---

---

title: About
description: A bit about AlignTrue.

---

# About AlignTrue

## What

AlignTrue keeps your AI rules in sync across agents, projects, and people.

- **Solo devs:** One source of truth for Cursor `.mdc`, `AGENTS.md`, `CLAUDE.md`, and whatever else you use.
- **Teams:** Shared rules that actually stay aligned across IDEs, agents, and repos, so best practices are practiced and not just vibes.

AlignTrue is [MIT licensed](LICENSE) and designed to be self-documenting. If something is broken, outdated, or missing, open a PR.

## Who

I'm [Gabe Mays](https://gmays.com/about/). I love building tools that close the gap between AI hype and real output.

## Why

I went deep with AI agents (especially when Sonnet 4.5 landed) and burned an irresponsible number of tokens fast. The power is obvious. So is the failure mode.

Most people aren't failing because AI is weak. They're failing because their guidance is scattered, inconsistent, and stale. Rules drift. Different agents see different instructions. Teams quietly invent their own "norms" and the AI just amplifies the chaos.

In regulated work, where you can't ship what you can't explain, I explored the problem from the interpretability side with [GlassAlpha](https://glassalpha.com). That surfaced a simpler, upstream issue: if your rules aren't aligned, nothing else is.

AlignTrue starts further upstream: Make it trivial to define, reuse, and sync rules everywhere so you get **leverage instead of chaos**.

It scratches my own itch, lays a foundation to execute the rest of for saner AI workflows, and it is open so we can push this forward together.
